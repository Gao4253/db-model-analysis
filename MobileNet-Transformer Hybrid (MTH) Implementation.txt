    # MobileNetV3 backbone with depthwise separable convolutions
    self.mobilenet = mobilenet_v3_small(pretrained=True)
    self.mobilenet.classifier = nn.Identity()  # Remove original classifier
    
    # Transformer branch with multi-head self-attention
    self.transformer = nn.TransformerEncoderLayer(
        d_model=embed_dim, nhead=num_heads, dim_feedforward=embed_dim*4)
    
    # Feature fusion module combining local and global features
    self.fusion = nn.Sequential(
        nn.Conv2d(embed_dim*2, embed_dim, kernel_size=1),
        nn.BatchNorm2d(embed_dim),
        nn.ReLU(inplace=True)
    )
    
    # Classification head
    self.classifier = nn.Sequential(
        nn.AdaptiveAvgPool2d(1),
        nn.Flatten(),
        nn.Linear(embed_dim, num_classes)
    )
    
def forward(self, x):
    # Extract local features using MobileNet
    local_feat = self.mobilenet(x)  # [B, 576, 7, 7]
    
    # Process through Transformer branch
    b, c, h, w = local_feat.shape
    global_feat = local_feat.flatten(2).permute(2, 0, 1)  # [HW, B, C]
    global_feat = self.transformer(global_feat)
    global_feat = global_feat.permute(1, 2, 0).view(b, c, h, w)
    
    # Fuse local and global features
    fused_feat = self.fusion(torch.cat([local_feat, global_feat], dim=1))
    
    # Final classification
    output = self.classifier(fused_feat)
    return output
