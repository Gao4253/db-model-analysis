class CSFTTrainer:
def init(self, model, device='cuda'):
self.model = model.to(device)
self.device = device
self.contrastive_module = ContrastiveLearningModule()
self.criterion = nn.CrossEntropyLoss()
def train(self, train_loader, val_loader, epochs=200, lr=0.001):
    optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=0.01)
    
    for epoch in range(epochs):
        self.model.train()
        total_loss = 0.0
        
        for batch_idx, (images, labels) in enumerate(train_loader):
            images = images.to(self.device)
            labels = labels.to(self.device)
            
            # Forward pass
            features = self.model.extract_features(images)  # Assume model has feature extraction
            logits = self.model.classify(features)
            
            # Compute losses
            cls_loss = self.criterion(logits, labels)
            contrastive_loss = self.contrastive_module(features, labels)
            total_loss = cls_loss + 0.5 * contrastive_loss  # Î»=0.5 as per paper
            
            # Backward pass
            optimizer.zero_grad()
            total_loss.backward()
            optimizer.step()
            
        # Validation phase
        val_acc = self.validate(val_loader)
        print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss.item():.4f}, Val Acc: {val_acc:.4f}')

def validate(self, val_loader):
    self.model.eval()
    correct = 0
    total = 0
    
    with torch.no_grad():
        for images, labels in val_loader:
            images = images.to(self.device)
            labels = labels.to(self.device)
            
            outputs = self.model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
    return correct / total
